# -*- coding: utf-8 -*-
"""mini14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bt_Nu7v9N7WVINqjgGXLPJaWscA8EYwV
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Sample data (replace this with your actual dataset)
data = pd.read_csv('Phishing1.csv')

# Feature extraction from URLs
def extract_features(url):
    features = {}
    features['url_length'] = len(url)
    features['num_special_chars'] = sum([1 for char in url if char in ['?', '&', '=', '-', '_', '.']])
    features['has_ip'] = int(any(char.isdigit() for char in url.split('/')))
    features['num_subdomains'] = url.count('.') - 1
    return features

# Apply feature extraction
url_features = data['id'].apply(lambda x: pd.Series(extract_features(x)))

# Combine the extracted features with the original data
data = pd.concat([data.drop('id', axis=1), url_features], axis=1)

# Encode the labels if they are categorical
label_encoder = LabelEncoder()
data['Label'] = label_encoder.fit_transform(data['Label'])

# Define features and labels
X = data.drop('Label', axis=1)
y = data['Label']

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)